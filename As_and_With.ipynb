{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":28536,"sourceType":"datasetVersion","datasetId":22219},{"sourceId":285947,"sourceType":"datasetVersion","datasetId":11496}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [SQL](https://www.kaggle.com/learn/intro-to-sql) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/as-with).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nYou are getting to the point where you can own an analysis from beginning to end. So you'll do more data exploration in this exercise than you've done before.  Before you get started, run the following set-up code as usual. ","metadata":{}},{"cell_type":"code","source":"# Get most recent checking code\n!pip install -U -t /kaggle/working/ git+https://github.com/Kaggle/learntools.git\n# Set up feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.sql.ex5 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T06:12:23.914045Z","iopub.execute_input":"2024-10-14T06:12:23.914474Z","iopub.status.idle":"2024-10-14T06:13:15.212914Z","shell.execute_reply.started":"2024-10-14T06:12:23.914431Z","shell.execute_reply":"2024-10-14T06:13:15.211820Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/Kaggle/learntools.git\n  Cloning https://github.com/Kaggle/learntools.git to /tmp/pip-req-build-wgj7e81d\n  Running command git clone --filter=blob:none --quiet https://github.com/Kaggle/learntools.git /tmp/pip-req-build-wgj7e81d\n  fatal: unable to access 'https://github.com/Kaggle/learntools.git/': Could not resolve host: github.com\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/Kaggle/learntools.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-wgj7e81d\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n  \u001b[31m╰─>\u001b[0m See above for output.\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n\n\u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/Kaggle/learntools.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-wgj7e81d\u001b[0m did not run successfully.\n\u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\nUsing Kaggle's public dataset BigQuery integration.\nSetup Complete\n","output_type":"stream"}]},{"cell_type":"markdown","source":"You'll work with a dataset about taxi trips in the city of Chicago. Run the cell below to fetch the `chicago_taxi_trips` dataset.","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"chicago_taxi_trips\" dataset\ndataset_ref = client.dataset(\"chicago_taxi_trips\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T06:13:39.138324Z","iopub.execute_input":"2024-10-14T06:13:39.138971Z","iopub.status.idle":"2024-10-14T06:13:39.661263Z","shell.execute_reply.started":"2024-10-14T06:13:39.138920Z","shell.execute_reply":"2024-10-14T06:13:39.660178Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Exercises\n\nYou are curious how much slower traffic moves when traffic volume is high. This involves a few steps.\n\n### 1) Find the data\nBefore you can access the data, you need to find the table name with the data.\n\n*Hint*: Tab completion is helpful whenever you can't remember a command. Type `client.` and then hit the tab key. Don't forget the period before hitting tab.","metadata":{}},{"cell_type":"code","source":"# Your code here to find the table name\ntables = list(client.list_tables(dataset))\n\nfor t in tables:\n    print(t.table_id)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T06:17:48.729467Z","iopub.execute_input":"2024-10-14T06:17:48.730298Z","iopub.status.idle":"2024-10-14T06:17:48.958996Z","shell.execute_reply.started":"2024-10-14T06:17:48.730253Z","shell.execute_reply":"2024-10-14T06:17:48.957779Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"taxi_trips\n","output_type":"stream"}]},{"cell_type":"code","source":"# Write the table name as a string below\ntable_name = 'taxi_trips'\n\n# Check your answer\nq_1.check()","metadata":{"execution":{"iopub.status.busy":"2024-10-14T06:18:34.178516Z","iopub.execute_input":"2024-10-14T06:18:34.179633Z","iopub.status.idle":"2024-10-14T06:18:34.188939Z","shell.execute_reply.started":"2024-10-14T06:18:34.179584Z","shell.execute_reply":"2024-10-14T06:18:34.187980Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.16666666666666666, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"1_GetTableName\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"markdown","source":"### 2) Peek at the data\n\nUse the next code cell to peek at the top few rows of the data. Inspect the data and see if any issues with data quality are immediately obvious. ","metadata":{}},{"cell_type":"code","source":"# Construct a reference to the \"global_air_quality\" table\ntable_ref = dataset_ref.table(table_name)\n\n# API request - fetch the table\ntable = client.get_table(table_ref)\n\nclient.list_rows(table, max_results=5).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2024-10-14T06:23:08.025583Z","iopub.execute_input":"2024-10-14T06:23:08.026010Z","iopub.status.idle":"2024-10-14T06:23:08.818277Z","shell.execute_reply.started":"2024-10-14T06:23:08.025970Z","shell.execute_reply":"2024-10-14T06:23:08.817239Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                 unique_key  \\\n0  9f895c32eb7ef473c8c03da76e99a803dfcab41a   \n1  f4c42db73e32ec8fd4814e5e22b4a1947d08c080   \n2  3d147cb3f85483a1c00c7d7e27742712bf1e8f8c   \n3  522ac1df4121f3249d82761e1b37c91521f4e923   \n4  93eb46600c3222a92d7d78cbac6ac35c42be9a77   \n\n                                             taxi_id  \\\n0  2130bc5fd239a4e3b304662424fb4cc7db0ca7abf78cc5...   \n1  2130bc5fd239a4e3b304662424fb4cc7db0ca7abf78cc5...   \n2  38205a7b4cb9cdabd0d6ee8c4c6b115c53e7bd7b06645a...   \n3  ac1045ae61a5226a9216bd9641b458bd9d7e7da0680ada...   \n4  78d45b51ff03d70f0ba2afda334acf93f678a179aaaaca...   \n\n       trip_start_timestamp        trip_end_timestamp  trip_seconds  \\\n0 2013-07-26 21:00:00+00:00 2013-07-26 21:00:00+00:00            60   \n1 2013-07-26 21:00:00+00:00 2013-07-26 21:00:00+00:00             0   \n2 2014-05-09 14:45:00+00:00 2014-05-09 14:45:00+00:00           120   \n3 2013-12-06 22:15:00+00:00 2013-12-06 22:30:00+00:00           840   \n4 2014-03-06 15:30:00+00:00 2014-03-06 15:45:00+00:00          1500   \n\n   trip_miles  pickup_census_tract  dropoff_census_tract  \\\n0        0.00                  NaN                   NaN   \n1        0.00                  NaN                   NaN   \n2        0.00                  NaN                   NaN   \n3        0.35                  NaN                   NaN   \n4        1.39                  NaN          1.703198e+10   \n\n   pickup_community_area  dropoff_community_area  ...  extras  trip_total  \\\n0                    NaN                     NaN  ...     NaN         NaN   \n1                    NaN                     NaN  ...     NaN         NaN   \n2                    NaN                     NaN  ...     NaN         NaN   \n3                    NaN                     NaN  ...     NaN         NaN   \n4                    NaN                    76.0  ...     NaN         NaN   \n\n   payment_type  company  pickup_latitude pickup_longitude pickup_location  \\\n0          Cash     None              NaN              NaN            None   \n1          Cash     None              NaN              NaN            None   \n2   Credit Card     None              NaN              NaN            None   \n3          Cash     None              NaN              NaN            None   \n4   Credit Card     None              NaN              NaN            None   \n\n   dropoff_latitude  dropoff_longitude                      dropoff_location  \n0               NaN                NaN                                  None  \n1               NaN                NaN                                  None  \n2               NaN                NaN                                  None  \n3               NaN                NaN                                  None  \n4         41.979071          -87.90304  POINT (-87.9030396611 41.9790708201)  \n\n[5 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique_key</th>\n      <th>taxi_id</th>\n      <th>trip_start_timestamp</th>\n      <th>trip_end_timestamp</th>\n      <th>trip_seconds</th>\n      <th>trip_miles</th>\n      <th>pickup_census_tract</th>\n      <th>dropoff_census_tract</th>\n      <th>pickup_community_area</th>\n      <th>dropoff_community_area</th>\n      <th>...</th>\n      <th>extras</th>\n      <th>trip_total</th>\n      <th>payment_type</th>\n      <th>company</th>\n      <th>pickup_latitude</th>\n      <th>pickup_longitude</th>\n      <th>pickup_location</th>\n      <th>dropoff_latitude</th>\n      <th>dropoff_longitude</th>\n      <th>dropoff_location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9f895c32eb7ef473c8c03da76e99a803dfcab41a</td>\n      <td>2130bc5fd239a4e3b304662424fb4cc7db0ca7abf78cc5...</td>\n      <td>2013-07-26 21:00:00+00:00</td>\n      <td>2013-07-26 21:00:00+00:00</td>\n      <td>60</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Cash</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>f4c42db73e32ec8fd4814e5e22b4a1947d08c080</td>\n      <td>2130bc5fd239a4e3b304662424fb4cc7db0ca7abf78cc5...</td>\n      <td>2013-07-26 21:00:00+00:00</td>\n      <td>2013-07-26 21:00:00+00:00</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Cash</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3d147cb3f85483a1c00c7d7e27742712bf1e8f8c</td>\n      <td>38205a7b4cb9cdabd0d6ee8c4c6b115c53e7bd7b06645a...</td>\n      <td>2014-05-09 14:45:00+00:00</td>\n      <td>2014-05-09 14:45:00+00:00</td>\n      <td>120</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Credit Card</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>522ac1df4121f3249d82761e1b37c91521f4e923</td>\n      <td>ac1045ae61a5226a9216bd9641b458bd9d7e7da0680ada...</td>\n      <td>2013-12-06 22:15:00+00:00</td>\n      <td>2013-12-06 22:30:00+00:00</td>\n      <td>840</td>\n      <td>0.35</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Cash</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93eb46600c3222a92d7d78cbac6ac35c42be9a77</td>\n      <td>78d45b51ff03d70f0ba2afda334acf93f678a179aaaaca...</td>\n      <td>2014-03-06 15:30:00+00:00</td>\n      <td>2014-03-06 15:45:00+00:00</td>\n      <td>1500</td>\n      <td>1.39</td>\n      <td>NaN</td>\n      <td>1.703198e+10</td>\n      <td>NaN</td>\n      <td>76.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Credit Card</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>41.979071</td>\n      <td>-87.90304</td>\n      <td>POINT (-87.9030396611 41.9790708201)</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### 3) Determine when this data is from\n\nIf the data is sufficiently old, we might be careful before assuming the data is still relevant to traffic patterns today. Write a query that counts the number of trips in each year.  \n\nYour results should have two columns:\n- `year` - the year of the trips\n- `num_trips` - the number of trips in that year\n\nHints:\n- When using **GROUP BY** and **ORDER BY**, you should refer to the columns by the alias `year` that you set at the top of the **SELECT** query.\n- The SQL code to **SELECT** the year from `trip_start_timestamp` is <code>SELECT EXTRACT(YEAR FROM trip_start_timestamp)</code>\n- The **FROM** field can be a little tricky until you are used to it.  The format is:\n    1. A backick (the symbol \\`).\n    2. The project name. In this case it is `bigquery-public-data`.\n    3. A period.\n    4. The dataset name. In this case, it is `chicago_taxi_trips`.\n    5. A period.\n    6. The table name. You used this as your answer in **1) Find the data**.\n    7. A backtick (the symbol \\`).","metadata":{}},{"cell_type":"code","source":"# Your code goes here\nrides_per_year_query = \"\"\"\n                        SELECT EXTRACT(YEAR FROM trip_start_timestamp) AS year, COUNT(1) AS num_trips\n                        FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n                        GROUP BY year\n                        ORDER BY year \n                        \"\"\"\n\n# Set up the query (cancel the query if it would use too much of \n# your quota)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nrides_per_year_query_job = client.query(rides_per_year_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nrides_per_year_result = rides_per_year_query_job.to_dataframe()\n\n# View results\nprint(rides_per_year_result)\n\n# Check your answer\nq_3.check()","metadata":{"execution":{"iopub.status.busy":"2024-10-14T06:35:27.406230Z","iopub.execute_input":"2024-10-14T06:35:27.407220Z","iopub.status.idle":"2024-10-14T06:35:30.500740Z","shell.execute_reply.started":"2024-10-14T06:35:27.407171Z","shell.execute_reply":"2024-10-14T06:35:30.499727Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"    year  num_trips\n0   2013   27217300\n1   2014   37395079\n2   2015   32385527\n3   2016   31756403\n4   2017   24979611\n5   2018   20731105\n6   2019   16476440\n7   2020    3888831\n8   2021    3947677\n9   2022    6382071\n10  2023    6495415\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.16666666666666666, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"3_YearDistrib\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"markdown","source":"### 4) Dive slightly deeper\n\nYou'd like to take a closer look at rides from 2016.  Copy the query you used above in `rides_per_year_query` into the cell below for `rides_per_month_query`.  Then modify it in two ways:\n1. Use a **WHERE** clause to limit the query to data from 2016.\n2. Modify the query to extract the month rather than the year.","metadata":{}},{"cell_type":"code","source":"# Your code goes here\nrides_per_month_query = \"\"\"\n                        SELECT EXTRACT(MONTH FROM trip_start_timestamp) AS month,\n                                COUNT(1) AS num_trips\n                        FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n                        WHERE EXTRACT(YEAR FROM trip_start_timestamp) = 2016\n                        GROUP BY month\n                        ORDER BY month\n                        \"\"\" \n\n# Set up the query\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nrides_per_month_query_job = client.query(rides_per_month_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nrides_per_month_result = rides_per_month_query_job.to_dataframe()\n\n# View results\nprint(rides_per_month_result)\n\n# Check your answer\nq_4.check()","metadata":{"execution":{"iopub.status.busy":"2024-10-14T06:45:06.905293Z","iopub.execute_input":"2024-10-14T06:45:06.905742Z","iopub.status.idle":"2024-10-14T06:45:08.695259Z","shell.execute_reply.started":"2024-10-14T06:45:06.905695Z","shell.execute_reply":"2024-10-14T06:45:08.694225Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"    month  num_trips\n0       1    2510389\n1       2    2568433\n2       3    2851106\n3       4    2854290\n4       5    2859147\n5       6    2841872\n6       7    2682912\n7       8    2629482\n8       9    2532650\n9      10    2725340\n10     11    2387790\n11     12    2312992\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.16666666666666666, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"4_MonthDistrib\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"markdown","source":"### 5) Write the query\n\nIt's time to step up the sophistication of your queries.  Write a query that shows, for each hour of the day in the dataset, the corresponding number of trips and average speed.\n\nYour results should have three columns:\n- `hour_of_day` - sort by this column, which holds the result of extracting the hour from `trip_start_timestamp`.\n- `num_trips` - the count of the total number of trips in each hour of the day (e.g. how many trips were started between 6AM and 7AM, independent of which day it occurred on).\n- `avg_mph` - the average speed, measured in miles per hour, for trips that started in that hour of the day.  Average speed in miles per hour is calculated as `3600 * SUM(trip_miles) / SUM(trip_seconds)`. (The value 3600 is used to convert from seconds to hours.)\n\nRestrict your query to data meeting the following criteria:\n- a `trip_start_timestamp` > **2016-01-01** and < **2016-04-01**\n- `trip_seconds` > 0 and `trip_miles` > 0\n\nYou will use a common table expression (CTE) to select just the relevant rides.  Because this dataset is very big, this CTE should select only the columns you'll need to create the final output (though you won't actually create those in the CTE -- instead you'll create those in the later **SELECT** statement below the CTE).\n\nThis is a much harder query than anything you've written so far.  Good luck!","metadata":{}},{"cell_type":"code","source":"# Your code goes here\nspeeds_query = \"\"\"\n               WITH RelevantRides AS\n               (\n                   SELECT EXTRACT(HOUR FROM trip_start_timestamp) AS hour_of_day,\n                           trip_miles, \n                           trip_seconds\n                   FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n                   WHERE  trip_start_timestamp > '2016-01-01' \n                           AND trip_start_timestamp < '2016-04-01'\n                           AND trip_seconds > 0 \n                           AND trip_miles > 0\n               )\n               SELECT hour_of_day, \n                       COUNT(1) AS num_trips, \n                       3600 * SUM(trip_miles) / SUM(trip_seconds) AS avg_mph\n               FROM RelevantRides\n               GROUP BY hour_of_day\n               ORDER BY hour_of_day\n               \"\"\"\n\n# Set up the query\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nspeeds_query_job = client.query(speeds_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nspeeds_result = speeds_query_job.to_dataframe() # Your code here\n\n# View results\nprint(speeds_result)\n\n# Check your answer\nq_5.check()","metadata":{"execution":{"iopub.status.busy":"2024-10-14T07:08:34.842873Z","iopub.execute_input":"2024-10-14T07:08:34.843349Z","iopub.status.idle":"2024-10-14T07:08:36.985395Z","shell.execute_reply.started":"2024-10-14T07:08:34.843305Z","shell.execute_reply":"2024-10-14T07:08:36.984311Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"    hour_of_day  num_trips    avg_mph\n0             0     203092  20.191744\n1             1     178046  18.628598\n2             2     143447  18.444370\n3             3     108899  19.273107\n4             4      80067  27.599669\n5             5      75786  33.065604\n6             6     102254  28.533112\n7             7     187585  19.884592\n8             8     284223  16.787900\n9             9     306854  18.434124\n10           10     279762  20.091309\n11           11     294006  20.926340\n12           12     311522  20.063901\n13           13     317225  19.766321\n14           14     312629  19.309655\n15           15     319953  18.515564\n16           16     349455  17.168814\n17           17     394324  14.641375\n18           18     431991  15.381995\n19           19     416743  17.795008\n20           20     356279  20.347398\n21           21     318363  22.584731\n22           22     289886  21.129847\n23           23     241690  20.259757\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.16666666666666666, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"5_TheLongQuery\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"markdown","source":"That's a hard query. If you made good progress towards the solution, congratulations!","metadata":{}},{"cell_type":"markdown","source":"# Keep going\n\nYou can write very complex queries now with a single data source. But nothing expands the horizons of SQL as much as the ability to combine or **JOIN** tables.\n\n**[Click here](https://www.kaggle.com/dansbecker/joining-data)** to start the last lesson in the Intro to SQL course.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-sql/discussion) to chat with other learners.*","metadata":{}}]}